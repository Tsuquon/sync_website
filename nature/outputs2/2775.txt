in november 2020, researchers in denmark published inconclusive results of a randomized trial to probe whether mask requirements protect against covid-19. although nearly 5000 people took part in the danmask study, it was too small, and its time frame too short, to answer the question. news reports, however, described the study results as questioning the efficacy of masks, and a june analysis noted that it fed into antimasking misinformation campaigns.now, another group argues such small, weak trials of public health measures can do more harm than good. writing in trials last month, the group argues such studies waste funding and time, and can give a dangerous appearance of certainty. much research does not lead anywhere that is useful, says co-author noah haber, an independent study design specialist. it’s noise at best, and it’s misinformation at worst, because it looks like information. other researchers, however, think any evidence is better than none.henning bundgaard, the lead danmask author, could not be reached for comment. however, in august in the annals of internal medicine, bundgaard and co-authors defended their sample size and methods, and said the study has been misinterpreted.there’s little doubt that small, weak studies have proliferated during the pandemic, which raised pressure to test interventions fast. a february nature communications analysis of 686 clinical covid-19 studies found they had poorer quality methods than a matched group of trials with similar study designs. a bmj review last month of 72 studies found hand washing and wearing masks reduced risk of sars-cov-2 infection, but it also said most of the studies had moderate to serious weaknesses. and a study led by haber, posted as a preprint in january, found that only one of 36 studies of covid-19 policies met four criteria that would make results useful for policymakers, such as tracking outcomes for long enough that policy measures had time to influence local infection rates.atle fretheim, a health services researcher at the norwegian institute of public health, thinks haber and his team are wrong to dismiss small studies completely. because relatively few people in a country or region are infected at any one time, impractically large sample sizes would be needed to study public health measures with certainty, he says.in march, fretheim argued in trials that studies like danmask can contribute to evidence when taken together. if face masks work, more or less, in all the 20 small, stupid trials that have been done, then we can probably agree that they seem to work.small studies can also play a crucial role in preventing waste, adds manoj lalu, an evidence quality researcher at the ottawa hospital research institute. they allow researchers to road-test crucial questions such as how to recruit participants or keep consistency across study sites before embarking on a study involving thousands of people.but hoping that someone will pick up the baton after a small trial is not a strong justification, says mcgill university bioethicist jonathan kimmelman. testing involving humans is only ethical when it can inform an important decision—like whether to launch a large trial following a pilot study, or whether to roll out vaccination after a large trial. running a small study without the intent to take it further comes with a range of harms, he says: you’re wasting volunteers’ time, there’s an opportunity cost, you’re putting out shit information that can only be misinterpreted by people who don’t know how to interpret it, and it’s only going to take time away from the people who do know how to interpret it.misinformation is a critical problem, haber and his co-authors say. any small, inconclusive study opens the door to misinterpretation, says emily smith, a george washington university epidemiologist and a co-author of haber’s. we live in the real world.there’s also the danger that policymakers will base decisions on single flawed studies, says kelly cobey, a metascientist at the university of ottawa heart institute. syntheses that pull together large bodies of evidence, like meta-analyses, aren’t the answer either: if the quality of the individual studies is poor, the quality of the synthesis is poor.haber and his co-authors agree that health measures such as wearing masks or school closures are difficult to study. that’s because of the complexities of studying human behavior—such as whether people wear masks routinely and correctly—and because small effects require huge populations, haber says. a high-quality trial on mask wearing is possible, he says, noting a massive trial in bangladesh, released as a preprint in may and published in science today. the trial, which had a large sample and careful design, reported small benefits. but it, too, has been criticized for its analysis methods and for overstating its findings.the pandemic has shown both the best and the worst of science, kimmelman says. vaccine trials and the large-scale recovery trial of treatments have been unbelievable, he says. but questions about mask wearing or the ideal timing of booster shots haven’t had the same resources or attention: we’ve discovered how piss-poor we are at answering certain kinds of questions that are of paramount importance for public health.