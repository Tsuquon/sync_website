weakly supervised deep-learning models for the analysis of whole-slide images from tumour biopsies perform better at prognostic tasks if the models incorporate context from the local microenvironment.you have full access to this article via your institution.recent developments in deep learning and the common availability of computing resources and digitized tissue slides have enabled the computational analysis of gigapixel whole-slide images (wsis)1. digital pathology and computational pathology offer hopes for more standardized and objective diagnoses, prognoses and predictions of therapeutic responses, and for the discovery of new morphological phenotypes of clinical relevance. however, for these to become reality, technical challenges that are inherent to pathology images must be overcome. on the one hand, wsis can be several gigapixels in size — and hence can be much larger than natural images — which limits the applicability (to computational pathology) of many algorithms that were developed for the analysis of conventional images. on the other hand, accurate representations of wsis need to incorporate information at multiple resolution scales, from fine-level morphological descriptions (such as cellular patterns) to coarse-level contextual information (such as tissue architecture and features of the tumour microenvironment). limited contextual information constrains the power of computational pathology for patient stratification and biomarker discovery. for example, the presence of immune cells may lead to different prognoses depending on whether the cells are in an inflammatory environment or an infiltrative one. moreover, the complexity of acquiring dense pixel-level annotations calls for the use of weakly supervised machine-learning strategies, such as assigning the label for the case to every small patch in a gigapixel image2, or the use of multiple-instance learning (mil) (that is, the use of labelled ‘bags of patches’)3,4.assigning a case label to every patch in an image can work well in cases wherein the region of interest corresponds to large portions of the image (as in large tumour resections) but results in too many noisy labels if only a tiny portion of the gigapixel image corresponds to the relevant region (as in lymph-node metastases)2,4. mil methods typically decompose the wsi into a set of patches (commonly referred to as a bag) that are passed through an encoder before being aggregated for wsi-level or patient-level diagnostic or prognostic predictions. as the number of patches can be really large (up to 20,000 for large resections, at an image magnification of 40×), most methods distinguish informative patches from irrelevant patches by assigning patch-level importance scores through an attention mechanism4. the drawback of this strategy is that each patch remains independent and that the context information remains limited to what is present in each patch. ad-hoc measures are commonly used to deal with this limitation, such as using larger patches to increase context (yet at the cost of increased computational complexity) or lowering the magnification level with the same patch size (at the cost of decreasing the patch resolution), which makes the granular patterns harder to detect.a more promising strategy is to represent histological tissues as graph structures5, wherein nodes represent image patches and nodes that are assumed to be statistically dependent are connected by edges. the topology of the graph is usually determined by a proximity function (in either physical space or latent space). the local context of the patch is included by transferring information along the edges of the graph neural network. this approach ensures that the desired coverage of context is captured at the desired magnification level and thus circumvents the context–resolution trade-off of the aforementioned ad-hoc measures. however, implementing graphs with tens of thousands of nodes, as required for gigapixel images, is challenging. in addition, the interpretation of any particular patch may vary depending on its surrounding context. sunghoon kwon and colleagues now report in nature biomedical engineering a graph neural network amenable for use with gigapixel wsis from tumour biopsies that allows for post-hoc model interpretability6. the researchers leveraged graph deep learning to incorporate the context provided by the tumour microenvironment, implemented a patch-aggregation strategy and edge-level attention to reduce the computational requirements, and show that the deep-learning model provides superior predictions and that it can be probed to uncover prognostic biomarkers.kwon and co-authors used wsis from haematoxylin-and-eosin-stained digital slides of biopsies from patients with clear cell renal cell carcinoma and explored three tasks: the prediction of patient survival, the risk of tumour recurrence and the risk of metastasis. the graph deep-learning model reached 88% accuracy in predicting mortality risk, stratified patients (according to predicted cancer grade) better than the use of the who/isup (world health organization/international society of urological pathology) grading system for renal cell carcinoma (particularly for early-stage cases) and performed better than state-of-the-art models (using contextual-feature learning or mil) in the prediction of disease progression (tumour recurrence or metastasis) for multiple patient cohorts.the superior performance of kwon and co-authors’ graph-deep-learning strategy stems from three key technical contributions. first, the use of aggregations of neighbouring patches with similar characteristics. such ‘superpatches’ bring about a memory-efficient representation that reduces the number of nodes and edges in the graph. second, the addition of edge features that encode the relative positions of the patches and that help contextualize the representations of the tumour microenvironment. third, the inclusion of an edge-level attention mechanism that allows for weighting the contributions of neighbouring patches and the identification of the relevant context. the authors also addressed model interpretability by studying its behaviour. they computed risk scores associated with each patch (that is, each node in the graph) for the prediction of prognostic biomarkers. they found that risk scores were correlated with prognostic predictions, which allowed for further probing of the model. studying the characteristics of patches associated with a certain level (high, medium or low) of a particular risk (mortality or tumour progression) allowed the authors to show that the graph neural network models known prognostic features (such as the different roles of immune cells according to the microenvironmental context of the tumour).the work of kwon and colleagues raises a particularly relevant question: are context-aware methods more robustly generalizable than those having access to less context? it is clear that context-aware methods bring a different paradigm for studying the tumour microenvironment and for discovering new biomarkers. however, analyses directed at biomarker discovery must go beyond qualitative considerations to quantitatively validate the findings and to ensure that they generalize to the entire cohort. this quantitative assessment requires integrating morphological-feature detectors to avoid the tedious and subjective manual inspection of each slide, and the derivation of metrics for the rigorous evaluation of the findings at the cohort level7.it is also important to understand where graph representations fit into the landscape of context-aware computational pathology (fig. 1). at one extreme, wsi patches are considered completely independent of each other and hence have no access to context (fig. 1a). at the other extreme, there are architectures (such as vision transformers (fig. 1c)) in which each patch has access to the whole context and interacts with all other patches, regardless of their position in the wsi8,9,10. because of the large number of patches in wsis, this approach has substantial computational overhead. in between the two extremes, there are graph representations and graph neural networks, such as that of kwon and colleagues (fig. 1b), in which patches interact according to predefined heuristically constructed connections. this ‘landscape’ of model types raises the question of what degree of inductive bias (which results from the set of assumptions made by the machine-learning model during training that allow it to provide inductive generalizations) is most appropriate for context awareness in machine-learning models for computational pathology. graph neural networks and the fully context-aware vision-transformer representation are attractive modelling choices. overall, graph representations have three advantages over vision transformers: better control over the interactions and contextual information used by the model, similarities of the locality principle embedded in the graph’s topology with the way biological systems interact, and lower computational complexity, owing to the smaller number of interactions. however, vision transformers can learn the locality principle in a data-driven manner. moreover, a lower inductive bias induces fewer constraints on the network and, therefore, transformers could have a higher chance of discovering new context-aware biomarkers. furthermore, ongoing work may lead to innovative methods that reduce the computational complexity of transformers, making it a practical research tool with global-context integration. rigorous comparisons of methods based on graphs or transformers, and by using large datasets and various pathology tasks (such as outcome prediction, tumour subtyping and metastasis detection), will be needed to find the optimal inductive bias.a, bag of independent tissue patches in multiple-instance learning. all patches are assumed to be independent and thus have no access to context. this approach has low computational complexity. b, graph-based approaches. each patch has access to context in its neighbourhood on the basis of pre-defined criteria. the pairs of numbers in between parentheses represent the relative orientation and distances between connected patches. c, transformer-based methods. every patch has access to the global context, and hence these methods require high computational resources. n, number of patches.bera, k. et al. nat. rev. clin. oncol. 16, 703–715 (2019).article google scholar coudray, n. et al. nat. med. 24, 1559–1567 (2018).cas article google scholar campanella, g. et al. nat. med. 25, 1301–1309 (2019).cas article google scholar lu, m. y. et al. nat. biomed. eng. 5, 555–570 (2021).article google scholar chen, r. j. et al. whole slide images are 2d point clouds: context-aware survival prediction using patch-based graph convolutional networks. in miccai 2021: medical image computing and computer assisted intervention (eds de bruijne, m. et al.) 339–349 (springer, 2021).lee, y. et al. nat. biomed. eng. https://doi.org/10.1038/s41551-022-00923-0 (2022).article pubmed google scholar jaume, g. et al. quantifying explainers of graph neural networks in computational pathology. in ieee/cvf conference on computer vision and pattern recognition (eds ieee staff) 8102–8112 (ieee, 2021).dosovitskiy, a. et al. an image is worth 16x16 words: transformers for image recognition at scale. in international conference on learning representations 2021 paper 1909 (iclr, 2021).shao, z. c. et al. transmil: transformer based correlated multiple instance learning for whole slide image classification. in advances in neural information processing systems 34 (eds ranzato, m., beygelzimer, a., dauphin, y., liang, p. s. & wortman vaughan, j.) 2136–2147 (neurips, 2021).chen, r. j. et al. scaling vision transformers to gigapixel images via hierarchical self-supervised learning. in ieee/cvf conference on computer vision and pattern recognition (eds ieee staff) 16144–16155 (ieee, 2022).download referencesdepartment of pathology, brigham and women’s hospital, harvard medical school, boston, ma, usaguillaume jaume, andrew h. song & faisal mahmooddepartment of pathology, massachusetts general hospital, harvard medical school, boston, ma, usaguillaume jaume, andrew h. song & faisal mahmoodcancer program, broad institute of harvard and mit, cambridge, ma, usaguillaume jaume, andrew h. song & faisal mahmooddata science program, dana-farber cancer institute, boston, ma, usaguillaume jaume, andrew h. song & faisal mahmoodharvard data science initiative, harvard university, cambridge, ma, usafaisal mahmoodyou can also search for this author in pubmed google scholaryou can also search for this author in pubmed google scholaryou can also search for this author in pubmed google scholarcorrespondence to faisal mahmood.the authors declare no competing interests.reprints and permissionsjaume, g., song, a.h. & mahmood, f. integrating context for superior cancer prognosis. nat. biomed. eng (2022). https://doi.org/10.1038/s41551-022-00924-zdownload citationpublished: 18 august 2022doi: https://doi.org/10.1038/s41551-022-00924-zanyone you share the following link with will be able to read this content:sorry, a shareable link is not currently available for this article. provided by the springer nature sharedit content-sharing initiative 