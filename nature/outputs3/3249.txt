neural networks can be implemented by using purified dna molecules that interact in a test tube. convolutional neural networks to classify high-dimensional data have now been realized in vitro, in one of the most complex demonstrations of molecular programming so far.you have full access to this article via your institution.convolution neural networks (convnets) are deep neural networks that sum (or integrate) the product of two functions that are continuously shifted relative to each other—this is called a convolution. this method was first applied inside a neural network in the early 1980s1 and has since become a workhorse algorithm in the field of computer vision2. indeed, one could argue that the success of convnets in the early 2000s was partially responsible for the end of the so-called ‘ai winter’ and the beginning of the boom in artificial intelligence research and applications that has continued to accelerate through the present day. in this issue of nature machine intelligence, xiong et al.3 have implemented a molecular convnet by means of dna strand-displacement (dsd) circuits, a commonly used paradigm in molecular programming4.the nascent field of molecular programming is a hybrid of nanotechnology, bioengineering and computer science. at the heart of this discipline, researchers attempt to embody algorithms in chemical interactions—or, in other words, build programs with molecules. so far, molecular programming has had the most success in simple in vitro systems with programs encoded in the interactions of dna strands and occasionally a few enzymes5. however, the field is rapidly expanding to include more programming substrates and prototypes of in vivo techniques6.dsd circuits, the molecular programming approach used by xiong et al.3, use the hybridization and dissociation between single-stranded dna molecules (usually under 100 nucleotides in length) to implement logical and mathematical operations5. typically, inputs to the molecular program are encoded as specific strands of dna that are added to a reaction mixture containing carefully designed dna complexes made up of multiple dna strands bound together. the program runs as these pieces of dna interact, binding and unbinding in various ways until one or more fluorescent reporting signals are produced.in an impressive demonstration of molecular programming, xiong et al. produced a large dna circuit comprising more than 500 different molecules that was capable of classifying 144-bit images into 32 categories. initially, the team trained four different convnets in silico to each classify a different set of eight 12 x 12 black-and-white images consisting of chinese oracle bone characters, arabic numerals, english letters and greek letters, respectively. the parameters of each of these neural networks were represented as the concentrations of ‘weight’ molecules that, along with other dna molecules representing the convnet architecture and input image, encoded the entire molecular implementation of the previously trained convnet. this in vitro dsd circuit ran in two stages (see fig. 1). first, each image was classified, using a boolean circuit, as chinese, arabic, english or greek. the stage 1 circuit released carefully controlled amounts of the weight molecules, which were then captured via magnetic beads and moved to stage 2, another reaction mixture containing the molecular convnet. upon addition of the correct weights, the dna strands in this mixture were able to successfully classify each of the eight images of a given type, as depicted in the figure.classification occurs in two steps. first, a molecular program consisting of interacting dna strands produces different kernel parameters, encoded as weight molecules, corresponding to whether the image shows a chinese, arabic, english or greek character, as represented by the different colours in the kernel functions produced from the leftmost boxes. second, weight strands are purified and transferred to a second molecular program encoding a convnet, which classifies each image as one character, as shown on the far right. figure adapted from ref. 3, springer nature.this work continues a trend of increasing complexity coupled with more streamlined designs in dsd circuits: xiong et al.3 were able to classify more and larger images using a molecular implementation with a greater number of total dna strands than had been done in earlier similar work, while simultaneously using fewer total strands per classification category7,8. to accomplish this task, the team developed a novel architecture that allows the weight molecules to be shared between different input bits. weight sharing is at the heart of how convolutions function, but it also allows a more compact molecular program. however, despite these gains, most dsd circuits of this size only function at exceptionally low molecular concentrations, interacting over long periods of time (typically around a day), to avoid spurious interactions known as ‘leak’, which can be incredibly detrimental to circuit performance. xiong et al. did not want to wait this long; in the process of this work, they also developed a new experimental protocol involving freeze–thaw cycles that dramatically accelerated the dsd reaction so that a computation could occur in as little as 30 minutes with minimal detriment to the accuracy of the program.the weight-sharing motif and freeze–thaw cycles represent significant advances in molecular programming. however, the fact that the program had to be run in two separate reactions with a purification step in the middle indicates that leak still remains a significant challenge for this dna convnet implementation. one obvious next step is the design of one-pot, multistage molecular classifiers that do not require any purification steps.taking a broader view, this work further illustrates that diverse neural architectures are readily implemented with biochemical components such as dsd circuits. in vitro dsd circuits like those used in this work could be developed into powerful molecular diagnostic devices and sensors capable of internal processing and classification. eventually, similar systems may also be deployed in vivo. it is also possible that biological circuitry has evolved to perform computations similar to classification—in short, that neural networks may be a model for how molecular networks compute.fukushima, k. & miyake, s. in competition and cooperation in neural nets (eds amari, s. & arbib, m. a.) 267–285 (springer, 1982).gu, j. et al. pattern recognition. 77, 354–377 (2018).article google scholar xiong, x. et al. nat. mach. intell. https://doi.org/10.1038/s42256-022-00502-7 (2022).zhang, d. y. & seelig, g. nat. chem. 3, 103–113 (2011).article google scholar seeman, n. c., hanadi, f. & sleiman, h. f. nat. rev. mater. 3, 1–23 (2017). google scholar jones, t. s. et al. nat. protoc. 17, 1097–1113 (2022).article google scholar qian, l., winfree, e. & bruck, j. nature 475, 368–372 (2011).article google scholar cherry, k. m. & qian, l. nature 559, 370–376 (2018).article google scholar download referencescomputation and neural systems, california institute of technology, pasadena, ca, usawilliam pooleyou can also search for this author in pubmed google scholarcorrespondence to william poole.the author declares no competing interests.reprints and permissionspoole, w. in vitro convolutional neural networks. nat mach intell 4, 614–615 (2022). https://doi.org/10.1038/s42256-022-00508-1download citationpublished: 11 july 2022issue date: july 2022doi: https://doi.org/10.1038/s42256-022-00508-1anyone you share the following link with will be able to read this content:sorry, a shareable link is not currently available for this article. provided by the springer nature sharedit content-sharing initiative 