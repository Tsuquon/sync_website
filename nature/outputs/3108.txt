microscopy-based drug screens with fluorescent markers can shed light on how drugs affect biological processes. without adding markers and imaging channels, which is cumbersome and costly, a new generative deep-learning method extracts new fluorescence channels from images, potentially improving the drug-discovery pipeline.you have full access to this article via your institution.scientists screen extensive collections of chemical or biological compounds to find new and effective medicines against human diseases. such screening involves exposing thousands of cells, from cancer cell lines or other models, to potential drug compounds and recording the cells’ responses to the treatment. however, to identify compounds that trigger a desired response, the most suitable measured properties of the cells (phenotypes) must be identified and harnessed to their maximum efficacy because screening procedures are time- and labour-intensive, costing tens to hundreds of thousands of dollars over months. this often means that a second or third screening of the compound library is too expensive. the method presented by wong et al. in this issue of nature machine intelligence, which teaches an encoder–decoder model to predict and generate fluorescence signals from existing signals1, overcomes these limitations.fluorescence microscopy is the method of choice to gain as much independent information on each treatment as possible. in essence, it uses chemical or biological probes that specifically bind a compartment or building block of a cell in its active (for example, phosphorylated) or inactive form. tagged to fluorescent molecules and chosen depending on the problem to be evaluated (such as the disease to be treated), these staining procedures can enhance image contrast by masking all excess signals and highlighting the most relevant cellular processes. this signal is captured with expensive fluorescence microscopy equipment using appropriate filter sets specific to each fluorescent molecule. the number of different fluorescence channels that can be captured simultaneously in a single readout is limited because of engineering constraints and the need to avoid spectral overlap. the images are used to measure the cellular phenotypes of each cell and serve as the basis for ranking drug treatments to evaluate candidates for downstream analyses.such detailed screening assays are costly and time-intensive, and much effort goes into optimizing the procedures. in studies ranking drug compounds across a more comprehensive array of phenotypes simultaneously, compounds are profiled and compared among each other to cluster and identify similarly active compounds and groups of compounds with related modes of action. wong et al. explored the possibility of training an algorithm to computationally perform the contrast enhancement through the prediction of specific new fluorescence channels1 based on previously measured screening assays.the authors developed this idea using the example of a drug-screening campaign to fight alzheimer’s disease. they built a model able to significantly increase the screen’s hit rate (that is, the proportion of compounds confidently ranked high for downstream validation) compared to more traditional state-of-the-art methods. to this end, they employed a widely used image-in, image-out architecture known as a u-net. this neural network architecture comprises a five-layer-deep encoder network followed by a decoder network that converts predictions back into the image pixel domain (fig. 1). to train the network, they used previously acquired reference screening data in which all fluorescence channels had been measured experimentally. then, using the measured channels (dna and pan-tau), they predict the phosphorylated tau (ptau) protein (a protein suspected to drive alzheimer’s disease progression2). they could use this prediction of the specific (and much more expensive) marker responses to improve the hit ranking for downstream validation experiments.in trans-channel fluorescence learning (schematic illustration), images from one imaging modality are used to predict additional imaging modes on the same specimen in silico. this approach uses a deep encoder–decoder (u-net) architecture to predict the resulting images from input images of biological specimens. here, three representative fluorescence channels staining dna (blue), α-tubulin (green) and actin (red) are extracted from brightfield images of single hap1 cancer cells. wong et al. profiled the additional information in the predicted channel to enhance hit selection in a high-throughput drug screening campaign against alzheimer's disease1, thereby paving the way toward the widespread use of trans-channel learning in drug discovery.after showing that the u-net can indeed predict the missing ptau channel accurately, the authors took the concept further and showed that extracting information from the additionally predicted channel increased the hit rate of the drug screen by about twofold. from a drug-discovery perspective, this is a significant improvement, as drug attrition rates are high and subsequent validation experiments require extensive labour and resources. finally, wong et al. tested the generalizability of this idea on the analysis of cell-cycle markers predicted from measured dna-marker-stained imagery from another cancer cell line1. again, this increased the hit rate of the previously published data set, implying that trans-channel learning is a generally applicable way to increase the information gained from high-content assays.it is intriguing to hypothesize that these approaches could be harnessed to increase microscopy image quality and information content. on the one hand, by tapping into previously published large collections of image-based genomic or drug screening data, one could, for example, rescue hits that have been missed in the state-of-the-art analyses. on the other hand, researchers could now have a tool that (assuming that there is enough training data to adapt the model to the new domain) can swiftly extract more information from each image, similar to the previously proposed approaches of content-aware image restoration (care3) and in silico fluorescence staining4.there remains the question of whether the prediction of the new fluorescence channel provides a vision of missing, additional data that have not been measured, or whether the u-net is performing a weighted extraction of denoised information from the experimentally measured channels. previous discussions argued for the latter case, in which the deep neural network architectures are mere information extraction machines that help researchers highlight and understand previously missed information. intuitively, this makes sense, as fluorescence staining can be understood as a chemical method to increase the contrast in microscopy images, a process that artificial intelligence could, in principle, learn to perform, given enough qualitative training data and a clear problem definition. however, one could argue that (i) generating an additional image and extracting information again leads to information loss compared to using the model to obtain the hit classification directly, and (ii) the approach poses the danger of hallucinating data that do not reflect reality and increases the chance of false-positive results. future studies will be needed to iteratively sanitize predictions and prove their value for accelerating drug discovery.the future of genomic screening and drug discovery certainly lies in the hands of scientists who can efficiently utilize machine learning to improve precision and throughput in screening for new drugs to fight the diseases we cannot cure5. to this end, models and data alike should be openly shared so that independent researchers can evaluate them carefully to reduce bias, increase generalizability and obtain safer drugs for less money in a shorter time.wong, d. r. et al. nat. mach. intell. https://doi.org/10.1038/s42256-022-00490-8 (2022).article google scholar sjögren, m. et al. j. neurol. neurosurg. psych. 70, 624–630 (2001).article google scholar weigert, m. et al. nat. methods 15, 1090–1097 (2018).article google scholar christiansen, e. m. et al. cell 173, 792–803.e19 (2018).article google scholar chandrasekaran, s. n., ceulemans, h., boyd, j. d. & carpenter, a. e. nat. rev. drug discov. 20, 145–159 (2021).article google scholar download referencesdivision of signaling and functional genomics, german cancer research center, heidelberg, germanyflorian heigwerdepartment of cell and molecular biology, medical faculty mannheim, heidelberg university, heidelberg, germanyflorian heigweryou can also search for this author in pubmed google scholarcorrespondence to florian heigwer.the author declares no competing interests.reprints and permissionsheigwer, f. learning the missing channel. nat mach intell 4, 616–617 (2022). https://doi.org/10.1038/s42256-022-00514-3download citationpublished: 20 july 2022issue date: july 2022doi: https://doi.org/10.1038/s42256-022-00514-3anyone you share the following link with will be able to read this content:sorry, a shareable link is not currently available for this article. provided by the springer nature sharedit content-sharing initiative 