as a data-science librarian at the university of california, san diego, stephanie labou has seen her share of spreadsheet horror stories. the most haunting was a table of hand-entered gps coordinates.it was a complete mix, labou recalls. the spreadsheet was produced by citizen-scientists. some had written the word ‘degrees’, some ‘0’ and some ‘o’; some had used superscripts, some hadn’t; others wrote ‘north’, ‘west’ or neither. we’re talking like tens of thousands of rows of data, where every single latitude and longitude was annotated differently, she says. that was the least consistent spreadsheet i’ve ever seen.data scientists express strong feelings about using spreadsheets for data analysis. on the whole, they prefer programming languages such as r and python, in which analyses are more easily documented and more reproducible. but many researchers are more comfortable with spreadsheets, and being shamed for using them is counterproductive, says labou. sometimes, spreadsheets are the fastest way to solve a problem. and there is really no other option for recording tabular data.spreadsheets are reactive: cells that depend on other cells will update automatically as the data change. they can also be helpful, intelligently formatting data to make them easier to read. plus, they are everywhere. spreadsheets are where data science begins, says tracy teal, open source program director at the software developer rstudio in boston, massachusetts.but they are also trickier than they seem. a function to take the average of a column, for instance, will return the wrong value if the formula fails to account for the correct data range. cells that seem empty might not be. and autoformatting doesn’t always work as expected. researchers have long known that some genomic studies contain garbled data because excel improperly converted some gene symbols, such as oct4, into dates. an analysis of around 11,100 papers published between 2014 and 2020 found that 31% still include such errors (m. abeysooriya et al. plos comput. biol. 17, e1008984; 2021).as data scientists karl broman at the university of wisconsin–madison and kara woo, then at the university of washington, seattle, wrote in 2018: spreadsheets, for all of their mundane rectangularness, have been the subject of angst and controversy for decades (k. w. broman and k. h. woo am. stat. 72, 2–10; 2018).here are six tips for using them correctly.christie bahlai, a computational ecologist at kent state university in ohio, has helped to create workshops and teaches courses on best spreadsheet practices for ecologists. she says her number-one piece of advice is to keep your raw data raw. a toolkit for data transparency takes shapespreadsheets, bahlai says, are tactile: they are user-friendly, intuitive and easily manipulated. but they are also easy to mess up, and it is easy to lose track of what you’ve done. an errant mouse click can cause data to end up in the wrong place. and the autoformatting function can ruin the data. furthermore, the spreadsheet can contain organization information that might not be immediately clear. as a result, bahlai recommends that users make their original spreadsheet a read-only document and work on copies, so that they can start over if necessary.bahlai recalls one case in which she kept finding single letters in one of the spreadsheet’s columns as she began to process the data. i’m like, ‘what does ‘m’ mean? what does ‘a’ mean?’ it turns out that a team member had typed ‘no sample’ vertically in one of the columns, one letter per row — an organization decision that is clear to a human reader, but not a computer. when she sorted the table, that visual organization was lost. it was like solving a jumble, she says with a laugh. i realized, ‘oh, this spells something, there’s a message!’spreadsheets provide extensive formatting options, from font styling to background fills to borders. this digital ‘bling’ can liven up a table and make it more readable. but when researchers use such styling to encode data, they can run into trouble.my top piece [of advice] is, do not encode data with colour or formatting, create another column that can be sorted or filtered, says mine çetinkaya-rundel, a statistician at duke university in durham, north carolina.that is because cell formatting is difficult for downstream users to capture. all the tools available to data scientists are unaware of data expressed as formatting rather than as text or numeric values, says duncan garmonsway, a data scientist in the uk government digital service in lincoln. formatting can be lost during routine table manipulations. and researchers might struggle to remember what the formatting represents when they return to the spreadsheet months or years later.luis verde arregoitia, a mammalogist at the institute of ecology (inecol) in veracruz, mexico, experienced that when he revisited an old collection of biodiversity records. he had highlighted rows in yellow, orange or green to indicate his level of trust in the data. at this point, he says, i don’t really remember the exact colour-coding scheme that i was using.data-analysis tools expect spreadsheets to be in a specific format: one row of column titles, no merged cells and one table per page. ideally, all cells are filled, even when there are no data (for instance, with ‘na’), and contain precisely one piece of data. to tabulate data from a field study to count insects, for instance, use separate columns for insect types and for the count, says teal, instead of, say, ‘3 red beetles’. coronavirus is spreading under the radar in us homeless sheltersspecialized tools can untangle spreadsheets that deviate from the ideal. verde arregoitia’s ‘unheadr’ package, for instance, handles tables that include rows to subdivide a table into different groups, which he calls ‘embedded subheaders’. garmonsway’s ‘tidyxl’ and rstudio data scientist jenny bryan’s ‘googlesheets4’ provide ways to extract the formatting.the most important thing, labou says, is consistency — decide on an approach, document it and stick to it. how will species be indicated? and how should dates be formatted — does ‘2/1/2022’ mean 1 february or 2 january? most experts recommend either the yyyy-mm-dd format — the international organization for standardization standard — or dedicating separate columns to year, month and day. when combined with data validation, the use of separate columns means there’s absolutely no ambiguity, labou says. but, warns broman, it does make it more difficult to compute date differences.whereas programming scripts can be saved and version-controlled, keystrokes and mouse-clicks generally cannot be. but spreadsheet users can still document their analyses.designate a spreadsheet (or tab) as a ‘code book’ that documents abbreviations, how data were collected, units of measurement, how missing values will be represented, the calculations being performed and any metadata needed to understand, process and maintain the spreadsheet. writing a roadmap for yourself is important, says çetinkaya-rundel.then, says bahlai, write the recipe of what you’ve done to your data. what does each formula do, and where does it draw its data from? you will regret it if, when you go to write your methods and you go, ‘huh, how did i take the average of this?’ she says. (in excel, you can use the ‘audit’ function to see the flow of data through the formulae, notes felienne hermans, a computer scientist at leiden university in the netherlands.)data analysts often add cross-checks to ensure that their data-processing code works as expected. spreadsheet users can do something similar, says hermans.in a study with samples from both cases and controls, for instance, the total number of values in the two groups should always equal the number of samples; if nothing else, that cross-check ensures that cells that you think are empty actually are. building in some of these cross-checks so you can see that everything is in order, that’s actually a really, really good idea, she says. naturetech hubyou can also ‘protect’ parts of the spreadsheet from modification, and apply data validation to ensure that date columns contain valid dates, that numbers fall within certain ranges or that text fields include expected terms. alternatively, suggests çetinkaya-rundel, use a data-entry form (such as a google form) rather than editing the spreadsheet directly. that way, values can be checked as they are entered, and users cannot accidentally modify the document. finally, says teal, double-check your work. data analysis is often iterative, she notes. you don’t just walk in the door and go, ‘i am going to do this equation,’ sit down, do it, done. so, once you’ve settled on a workflow, reset and start over, she says, and just make sure that you have the answer that you thought you did.the good news is, data scientists can generally wrangle spreadsheets irrespective of their format. a key principle that i have as a data analyst is, if someone asks me in what form would i like the data, i always say ‘in their present form’, says broman. if the data need to be reorganized or transformed in some way, i’m always in the best position to do that. but it’s better, labou says, to work out what you hope to do with your data before creating your spreadsheet in the first place. which variables and covariates will you be using? what time steps do you need? what analyses will you be performing? thinking that through ahead of time, is one of the best things that people can do, she says.and consult your collaborators, garmonsway adds. rules for data organization aren’t carved in stone anywhere, he says. physicists didn’t discover them in the fundamental laws of the universe. they emerged because it’s hard to work with other people. so if you collaborate when you create your spreadsheet, it’s much more likely to be useful to other people, because it’s already useful to someone who isn’t you.