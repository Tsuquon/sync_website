prosthetic arms are getting ever more sophisticated. now they just need a sense of touch.sitting motionless in her wheelchair, paralysed from the neck down by a stroke, cathy hutchinson seems to take no notice of the cable rising from the top of her head through her curly dark hair. instead, she stares intently at a bottle sitting on the table in front of her, a straw protruding from the top. her gaze never wavers as she mentally guides a robot arm beside her to reach across the table, close its grippers around the bottle, then slowly lift the vessel towards her mouth. only when she finally manages to take a sip does her face relax into a luminous smile.this video of 58-year-old hutchinson illustrates the strides being taken in brain-controlled prosthetics1. over the past 15 years, researchers have shown that a rat can make a robotic arm push a lever2, a monkey can play a video game3 and a person with quadriplegia — hutchinson — can sip from a bottle of coffee1, all by simply thinking about the action. improvements in prosthetic limbs have been equally dramatic, with devices now able to move individual fingers and bend at more than two dozen joints.but hutchinson's focused stare in that video also illustrates the one crucial feature still missing from prosthetics. her eyes could tell her where the arm was, but she could not feel what it was doing. nor could she sense when the grippers touched the bottle, or whether it was slipping out of their grasp. without this type of sensory feedback, even the simplest actions can be slow and clumsy, as igor spetic of madison, ohio, knows well. fitted with a prosthetic after his right hand was crushed in an industrial accident in 2010, spetic describes breaking dishes, grabbing fruit too hard and bruising it and dropping a can when trying to pick it up at the local shop. having a sense of touch would be tremendous, he says. it'd be one step closer to having the hand back.prosthetics researchers are now trying to grant him that wish by creating prosthetics that can 'feel' more like the real thing. it is a daunting task: researchers have managed to read signals from the brain; now they must write information into the nervous system. touch encompasses a complicated mix of information — everything from the soft prickliness of a woollen top to the slipping of a sweaty soft-drink can. the research is still in its infancy, with approaches that range from stimulating nerves in a stump and re-routing nerves to other parts of the body, to tapping directly into the brain (see 'closing the loop'). but it's probably the next big thing that has to happen, says robert kirsch, a biomedical engineer at case western reserve university in cleveland, ohio. alternative senses conventional prosthetics are not devoid of feedback. the widely used 'split-hook' hand replacement, for instance, typically has a harness that lets the user open and close the device by moving another part of the body, such as the opposite shoulder; patients then feel resistance in the harness when they grab something. likewise, users of motorized prosthetics — which are controlled by electrical signals from muscles in the stump — will feel pressure on the stump when they push something, or may hear subtle changes in the motor's sound when grabbing an object. researchers have even tried to introduce such feedback deliberately, through vibrations, air pressure and electrical stimulation.but none of these sensations feels natural — which may be one reason that many people reject prosthetic limbs: the replacement just doesn't seem like part of the body.recreating life-like sensation is a tall order. the sensations arise from a host of receptors in the skin, which detect texture, vibration, pain, temperature and shape, as well as from receptors in the muscles, joints and tendons that contribute to 'proprioception' — the sense of where a limb is in space. prosthetics are being outfitted with sensors that can gather many of these sensations, but the challenge is to get the resulting signals flowing to the correct part of the brain.for people who, like spetic, have had limbs amputated, the obvious way to achieve that is to route the signals into the remaining nerves in the limb's stump. researchers including ken horch, a neuroprosthetics researcher at the university of utah in salt lake city, have done just that by threading electrodes into the nerves in stumps then stimulating them with a tiny current, so that patients felt like their fingers were moving or being touched4.the technique can even allow patients to distinguish basic features of objects: a man who had lost his lower arms was able to determine the difference between blocks made of wood or foam rubber by using a sensor-equipped prosthetic hand. he correctly identified the objects' size and softness more than twice as often as would have been expected by chance5. information about force and finger position was delivered from the prosthetic to a computer, which prompted stimulation of electrodes implanted in his upper-arm nerves. researchers at florida international university in miami are now working to build an implantable device using the technique.but some researchers worry that implanting electrodes directly into a nerve could damage it. dustin tyler, a biomedical engineer at case western reserve university, and his colleagues have therefore developed a cuff-like electrode that encircles the nerve. we want to get access to as much of the nerve as we can without actually penetrating into it, says tyler. the researchers showed that by running current to the cuffs in cats, they could precisely activate nerves and make the animals move their feet in specific directions6. they are now trying to stimulate nerves that carry sensory information. their first patient — spetic — had the cuffs implanted in his forearm last may, says tyler, and can feel very natural sensation at multiple spots. the team is now testing the electrodes in a second patient. complex sensation as promising as such results are, researchers will probably need to stimulate hundreds or thousands of nerve fibres to create complex sensations, and they will need to keep the devices working for many years if they are to minimize the number of surgeries required to replace them. so some researchers are instead trying to give patients sensory feedback by touching their skin.this technique was discovered by accident in 2002, when a group led by todd kuiken, director of the center for bionic medicine at the rehabilitation institute of chicago in illinois, was testing a way to improve patients' control of their prosthetic limbs. the idea was to rewire arm nerves that used to serve the hand, for example, to muscles in other parts of the body. when the patient thought about closing his or her hand, the newly targeted muscle would contract and generate an electric signal, driving movement of the prosthetic. it'd be one step closer to having the hand back. the first patient to receive this 'targeted reinnervation' therapy was jesse sullivan, a power-line engineer who had lost both arms from electrical burns. after his arm nerves were re-routed to his chest muscles, sullivan could operate a prosthetic hand just by thinking about the actions. but to everyone's surprise, he also began to feel as though his missing hand was being touched when his chest was touched. it turned out that the re-routed nerves had grown into the chest skin, and his brain was interpreting the sensory signals as coming from his hand. some parts of his chest felt like his palm, whereas others felt like his fingers or forearm7.the results raised the possibility that sensory information from a prosthetic could be delivered to a device that pushes different parts of the skin. for people who have had targeted reinnervation surgery, pressure on the newly wired skin would then trigger sensations of touch in the missing hand. the technique isn't perfect: the parts of the hand don't map neatly onto the reinnervated skin, and each patient has a different map. and delivering detailed sensory information from a prosthetic can be challenging, as the area for stimulation is limited to a small patch of skin. but even so, one of kuiken's former colleagues is working with the company hdt robotics in evanston, illinois, to make such a device, and kuiken plans to develop one as well. direct hit none of these techniques will work for people who, like hutchinson, have had a stroke, or received spinal-cord injuries that severed the nerve pathways from the limbs to the brain. so some researchers are skipping directly to the brain. in principle, this should be straightforward. because signals from specific parts of the body go to specific parts of the brain, scientists should be able to create sensations of touch or proprioception in the limb by directly activating the neurons that normally receive those signals.this is immensely difficult to do, however, because scientists still have an incomplete knowledge of which neurons those are. researchers therefore have two options: identify and mimic the natural signals, or make the brain learn a new set.a team led by sliman bensmaia, a neuroscientist at the university of chicago, is taking the first approach. in one study, the researchers repeatedly poked monkeys in two spots on the hand and trained the animals to move their eyes left or right, depending on whether the second poke was to the left or right of the first one. they then placed electrodes in the monkeys' brains and mapped which parts of the brain responded as they touched the different spots.next, the researchers simulated a poke by sending current to the neurons that had been activated when the monkey was touched on the little finger. the animals moved their eyes as if their finger had actually been poked, says bensmaia, who reported the results at the society for neuroscience's 2012 meeting in new orleans, louisiana.miguel nicolelis, a neuroscientist at duke university school of medicine in durham, north carolina, favours the second approach. he and his colleagues trained monkeys to direct a virtual hand around a computer screen — and to touch on-screen objects — using their thoughts alone8. when the hand rubbed a 'rough' object, the team sent low-frequency electrical pulses to the monkey's brain; for a 'smooth' object, it sent a high-frequency signal.over time, the monkey learned to pick the right object from the frequency of the signal its brain received, and could essentially 'feel' the objects on screen. nicolelis hopes that he can use the same tactic in people with prosthetics.but neither he nor bensmaia know whether the monkeys they tested felt poking, roughness or some other sensation such as tingling. they are feeling something for sure, nicolelis says, but what exactly they feel is inside their heads.irrespective of which signals are used, scientists will need a more finely tuned technique to deliver them. with electrical stimulation, all neurons close to the electrode's tip are activated indiscriminately, so even if i had the sharpest needle in the universe, that could create unintended effects, says arto nurmikko, a neuroengineer at brown university in providence, rhode island. for example, an attempt to create sensation in one finger might produce sensation in other parts of the hand as well, he says.nurmikko and other researchers are therefore using light, in place of electricity, to activate highly specific groups of neurons and recreate a sense of touch. they first used a technique called optogenetics to express genes for light-sensitive proteins in parts of a monkey's brain that receive tactile information from the hand. they then trained the monkey to remove its hand from a pad when the device vibrated. when the team then stimulated the brain with a light source implanted in the animal's skull, the monkey lifted its hand off the pad about 90% of the time, according to results reported at the society for neuroscience meeting. the use of such techniques in humans is still probably 10–20 years away, says bensmaia, but it is a promising strategy. approximations even if such techniques can be made to work, it is unclear how closely they will approximate natural sensations. tingles, pokes and vibrations are still a far cry from the complicated sensations that we feel when closing a hand over an apple, or running a finger along a table's edge.but patients don't need a perfect sense of touch, says douglas weber, a bioengineer at the university of pittsburgh in pennsylvania. simply having enough feedback to improve their control of grasp could help people to perform tasks such as picking up a glass of water, he explains. patients who wear cochlear implants, for example, are often happy to regain enough hearing to hold a phone conversation, even if they are still unable to distinguish musical subtleties.one of the most sophisticated devices to include sensory feedback is a prosthetic arm developed by researchers at the johns hopkins university applied physics laboratory in laurel, maryland. built as part of a us department of defense research programme that has spent us$144 million since 2006 to improve prosthetics for injured soldiers returning from iraq and afghanistan, the arm is equipped with more than 100 sensors that detect sensations ranging from pressure to temperature. scientists at the university of pittsburgh and the california institute of technology in pasadena are seeking regulatory approval to use brain stimulation to deliver sensory feedback from the prosthetic limb to patients.spetic, for one, can hardly wait to get hold of a prosthetic hand with a sense of touch. i'd probably lay everything on the countertop and just start grabbing stuff, he says. i'd be so excited i wouldn't even know where to begin.hochberg, l. r. et al. nature 485, 372–375 (2012).ads cas article google scholar chapin, j. k. et al. nature neurosci. 2, 664–670 (1999).cas article google scholar serruya, m. d. et al. nature 416, 141–142 (2002).ads cas article google scholar dhillon, g. s., lawrence, s. m., hutchinson, d. t. &amp; horch, k. w. j. hand surg. 29, 605–615 (2004).article google scholar horch, k., meek, s., taylor, t. g. &amp; hutchinson, d. t. ieee trans. neur. syst. rehab. eng. 19, 483–489 (2011).article google scholar tyler, d. j. &amp; durand, d. m. ieee trans. neural syst. rehab. eng. 10, 294–303 (2002).article google scholar kuiken, t. a., marasco, p. d., lock, b. a., harden, r. n. &amp; dewald, j. p. a. proc. natl acad. sci. usa 104, 20061–20066 (2007).ads cas article google scholar o'doherty, j. e. et al. nature 479, 228–231 (2011).ads cas article google scholar download referencesroberta kwok is a freelance science writer in seattle, washington., roberta kwokyou can also search for this author in pubmed google scholar fda approves first retinal implant 2013-feb-15  mind-controlled robot arms show promise 2012-may-16  monkey brains 'feel' virtual objects 2011-oct-05  artificial skins detect the gentlest touch 2010-sep-12  neuroprosthetics: in search of the sixth sense 2006-jul-12  biotechnology@nature.com  darpa's revolutionizing prosthetics  targeted reinnervation  johns hopkins university applied physics laboratory's modular prosthetic limb reprints and permissionskwok, r. neuroprosthetics: once more, with feeling. nature 497, 176–178 (2013). https://doi.org/10.1038/497176adownload citationpublished: 08 may 2013issue date: 09 may 2013doi: https://doi.org/10.1038/497176aanyone you share the following link with will be able to read this content:sorry, a shareable link is not currently available for this article. provided by the springer nature sharedit content-sharing initiative analog integrated circuits and signal processing (2018)scientific reports (2017)international journal of precision engineering and manufacturing (2017)nature materials (2016)medical & biological engineering & computing (2016)