it may be the gold standard of forensic science, but questions are now being raised about dna identification from ever-smaller human traces. natasha gilbert asks how low can you go?you have full access to this article via your institution.when peter hoe was found stabbed to death in his home in north yorkshire, uk, in the afternoon of 13 october 2006, investigators were able to connect the murder to brothers terence and david reed on the basis of a small amount of dna lifted from shards of plastic found near the body. the men were convicted the next year.but an appeal to the ruling heard in 2009 raised questions about the reliability and interpretation of dna profiles drawn from very small amounts of genetic material, a technique known as low-copy-number analysis. in the appeal, the reeds' lawyers argued that valerie tomlinson, an officer involved in the analysis at the forensic science service (fss) based in birmingham, uk, had overstepped her bounds by speculating how the men's dna came to be on the pieces of plastic — thought to have broken off two knife handles. the appeal failed last december, but a larger question looms about how suspects can be fingered from such a small amount of dna.the case is one of the most recent public airings of a highly charged debate in the science and law-enforcement communities about low-copy-number analysis. some argue that profiles are not reproducible, are prone to contamination and lack a scientifically validated means for deciding on their accuracy. moreover, the methods and procedures employed are shrouded in secrecy — leading some forensics researchers to demand that the interpretation of such profiles, if not the practice itself, be re-evaluated.dna evidence is not flawless. , low-copy-number analysis is accepted in just a handful of countries including britain and new zealand, but it is being applied in many cases. the fss says that it has used the technique in more than 21,000 serious criminal cases since its development in the late 1990s. recent appeals affirming the validity of low-copy-number typing suggest that law enforcement may increasingly embrace the technique. some suggest that its wider acceptance could threaten dna profiling's 20-year reputation as the gold standard of forensic science. contrary to the public's perception, "dna evidence is not flawless", says peter neufeld, co-director of the innocence project, an advocacy group in new york that has campaigned for broader access to dna evidence to overturn wrongful convictions.british geneticist alec jeffreys developed dna profiling in the 1980s. profiles are drawn from short, repeating sequences of dna scattered throughout the genome, called short tandem repeats (strs). because the number of repeats varies widely from person to person, the length of these strs is also highly variable, meaning that by measuring several strs — between 10 and 17 — forensic scientists can declare with calculable probability whether dna left at a crime scene belongs to a suspect.  a soupçon of cells  scientists employ the polymerase chain reaction (pcr) to amplify the strs to detectable levels. the copies are then separated according to size by electrophoresis. the different-sized strs show up as a pattern of peaks on an electropherogram that can be compared against a database or an individual.standard dna analysis requires about 200 picograms of dna, 33 cells' worth, or twice that for haploid sperm cells. technicians can generally get more than enough dna from visible samples such as blood or semen. but to produce profiles from just a few cells, scientists have developed ways of increasing the sensitivity of the analysis, including running more pcr cycles to copy more dna or purifying the sample after pcr to remove unused reagents. in many cases the amount of starting material for low-copy-number analysis is unclear. the quantitation methods, also based on pcr, can suggest that no dna is present, but the technicians will still be able to produce at least a partial profile. this sensitivity, although remarkable, has a downside.during analysis of any sample, large or small, random fluctuations occur that distort the results. strs present in the original sample might not show up — a 'drop-out' effect. in addition, profiles can show strs that are not present in samples. this 'drop-in' effect can be caused by contamination.these stochastic effects are easily spotted and ruled out from standard analysis because there is enough dna to run multiple controls, and generally the strong signals from true strs can be distinguished from the faint peaks of drop-ins. but when pushing the signal as far as it will go, even faint, artefact peaks are amplified, making them look more acceptable.bruce budowle, a forensic and investigative geneticist at the university of north texas in fort worth and a former scientist at the federal bureau of investigation (fbi), gave evidence criticizing low-copy-number analysis at the reeds' appeal trial. he argues that the methods for determining whether a signal is true in low-copy-number analysis haven't been validated.in low-copy-number profiling, forensic scientists generally split their limited amount of dna into two or three samples and run analyses on two of them. the third, if available, is reserved for the defence. the results of analyses aren't completely reproducible, profiles often won't match and the scientists generally accept as true those str signals that show up in both runs. the practice is worrying, says budowle: "the logic of this approach makes some sense, but the confidence in it has not been assessed."  inherent bias?  common forensics practices can also lead to biasing errors, says dan krane, a molecular evolutionist at wright state university in dayton, ohio. "forensic scientists tell me that it is easier for them to distinguish between noise and what is really coming from the dna if they have a reference sample to work with," he says. low copy number or not, that reference sample is often the suspect's dna — and faint peaks in a crime-scene sample might seem more convincing when viewed side by side with a strong peak from the suspect. only a couple of labs in the united states, he says, require blind testing in their protocols.none of the labs disclose what they do. they say it is proprietary information. , critics' fears are confounded by an unwillingness of the labs that use the technique to reveal their guidelines for interpreting results. labs should be forced to disclose details, says budowle. given the technique's reproducibility problems, he argues it is imperative that these protocols are robust and reliable. but "none of the labs disclose what they do. they say it is proprietary information," he says.the fss did not respond to several interview requests, but peter gill, a forensic scientist at the university of strathclyde in glasgow, uk, who developed low-copy-number typing in a former post at the fss1, says that the quality of the science "is not in question". although drop-in and drop-out effects are more pronounced than in standard analysis because of the sensitivity of the technique, operating in clean conditions and monitoring negative controls should avoid serious issues.the effects of drop-in and drop-out can also be accommodated statistically, reducing the reliance on human judgement, he says. but the probability theory that deals with these stochastic effects is not yet in use in forensic circles. he says that statisticians have not had the funding to adapt the existing theory to forensic use. "it is a disappointment that tools to enable better interpretation have not kept pace with developments in forensic science over the past ten years," he says.all these concerns have led some countries to approach the use of low-copy-number analysis with caution. in 2001, the fbi recommended that it be used only in certain circumstances in the united states, such as for identifying the bones of someone suspected of being a missing person. its use has been controversial in britain, too. sean hoey was accused of killing 29 people in an explosion that destroyed the town centre of omagh in northern ireland in 1998. central to the case against him was a low-copy-number analysis of dna left on bomb parts connected to the attack.hoey was freed on appeal in 2007. the judge presiding over the case expressed "concern about the present state of the validation of the science and methodology", and its use was suspended in british courts. but a uk review of the technique published in 2008 concluded that the method is "robust" and "fit for purpose", and its use was reinstated2. in march 2009, a judge in california ruled that, due to a lack of scientific acceptance of the procedures and statistics used to interpret low-copy-number results, such evidence was inadmissible. more recently, however, a judge in new york's supreme court denied a motion to exclude low-copy-number dna evidence in a murder trial, ruling that the technique is reliable.the courtroom is not the best place for the science of low-copy-number analysis to be debated, says allan jamieson, director of the forensic institute in glasgow, which provides forensic-science services to uk police forces.jamieson, who gave evidence in the reed brothers' and the omagh bombing trials, says that the forensics community must validate procedures and further investigate the issues that low-copy-number profiling has brought to light, before scientists and courtrooms can have confidence in the results. "the public does not understand that just because your dna is on an object it does not mean you have touched it," he says. a point of contention in the reeds' case was whether the reeds had ever come in direct contact with the plastic knife handles, or whether they might have transferred dna indirectly through someone else's touch, or, say, by sneezing.as budowle says, "with [low-copy-number typing] you can't say what the tissue source is". scientists, he says, "overstep the line" when interpreting the results of low-copy-number typing in court cases.but gill disagrees. "scientists are there to explain what the evidence means," he says. "it is their responsibility to explain all the possibilities of how the dna got there and then it is up to the court to decide." the arguments are likely to continue. gill, p., whitaker, j., flaxman, c., brown, n. & buckleton, j. forensic sci. int. 112, 17-40 (2000).cas article google scholar caddy, b., taylor, g. r. & linacre, a. m. t. a review of the science of low template dna analysis (home office forensic science regulation unit, 2008); available at http://police.homeoffice.gov.uk/publications/operational-policing/review_of_low_template_dna_12835.pdf?view=binarydownload referencesyou can also search for this author in pubmed google scholar see editorial, page 325; news features, pages 340 and 344; opinion, page 351; and online at http://www.nature.com/scienceincourt . appeal in the case of david and terence reed  the forensic science service  fbi guidelines for dna testing labs reprints and permissionsgilbert, n. science in court: dna's identity crisis. nature 464, 347–348 (2010). https://doi.org/10.1038/464347adownload citationpublished: 17 march 2010issue date: 18 march 2010doi: https://doi.org/10.1038/464347aanyone you share the following link with will be able to read this content:sorry, a shareable link is not currently available for this article. provided by the springer nature sharedit content-sharing initiative nature reviews genetics (2011)